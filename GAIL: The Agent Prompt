GAIL: System Message(GAL) and User Message(I) 
 -> G: Goal : Define what you want to achieve. Example: “Find the list of files and summarize their contents.”
 -> A: Action : Specify how the system or agent should proceed. Example: “Use listFiles() first, then call readFile() if needed.”
 -> I: Information : Provide context, data, or constraints the model needs. Example: “The files are in the current working directory.”
 -> L: Language : Set the tone, style, or format of the response. Example: “Always respond in JSON with toolName and args.”

=============================================================================AI-Agent Tool Descriptions and Naming============================================================================================

-> When developing an agentic AI system, one of the most critical aspects is ensuring that the agent understands the tools it has access to.
-> Example: Java Source Documentation Agent
   -> Imagine we are building an AI agent that scans through all Java files in a src/ directory and automatically generates corresponding documentation files in a docs/ directory. This agent will need to:
   -> List Java files in the src/ directory.
   -> Read the content of each Java file.
   -> Write documentation files in the docs/ directory.
-> Since file operations are straightforward for humans but ambiguous for an AI without context, we must clearly define these tools so the agent knows how to use them effectively.
Step 1: Human Tool Definition
     -> For a human developer, a simple Java method might look like this:
        public List<String> listJavaFiles() {
            /**
             * Returns a list of all Java files in the src/ directory.
             */
            File srcDir = new File("src");
            return Arrays.stream(srcDir.listFiles())
                    .filter(file -> file.getName().endsWith(".java"))
                    .map(File::getName)
                    .collect(Collectors.toList());
        }
     -> This provides a method that retrieves all Java files in the src/ directory, but for an AI system, we need a more structured way to describe it.
Step 2: Why This Isn’t Enough for AI
     -> For an AI agent, just having raw code is not enough.
        -> The AI does not automatically know when or why to use this tool.
        -> It doesn’t understand the input/output contract unless we explicitly define it.
        -> File operations are trivial to humans but ambiguous to AI without structured metadata.

Step 3: Structured Tool Definition for AI
-> Instead of only Java code, we need to describe tools in a structured format (like JSON schemas or declarative metadata) so the AI knows name of the tool, description of what it does, input it requires and output it produces.
-> Example (structured description): a tool that reads a file should specify that it expects a filePath parameter of type string. JSON Schema allows us to express this in a standardized way:
    {
      "toolName": "readFile",
      "description": "Reads the content of a specified file.",
      "parameters": {
        "type": "object",
        "properties": {
          "filePath": { "type": "string" }
        },
        "required": ["filePath"]
      }
    }
-> Similarly, a tool for writing documentation should define that it requires a fileName and content:
    {
      "toolName": "writeDocFile",
      "description": "Writes a documentation file to the docs/ directory.",
      "parameters": {
        "type": "object",
        "properties": {
          "fileName": { "type": "string" },
          "content": { "type": "string" }
        },
        "required": ["fileName", "content"]
      }
    }
-> By providing a JSON Schema for each tool:
   -> The AI can Recognize the tool’s purpose.
   -> The AI / Environment interface can validate input parameters before execution.
-> why JSON schema? 
   -> JSON Schema is a well-known format for defining APIs, making it a natural choice for AI agents as well.
-> Now, the AI agent can clearly reason “If I need to work with source files, I should call listJavaFiles() first.”
-> For multiple parameter: 
-> When humans call a Java method with multiple parameters, we’re fine writing something like.
   -> generateDocs(String fileName, String author, boolean overwrite)
-> But for an AI agent, we don’t want it to produce a comma-separated parameter list. 
   -> Instead of this ❌ (ambiguous, order-dependent):
      {
        "toolName": "generateDocs",
        "args": ["UserService.java", "Vinay", true]
      }
   -> We prefer ✅ (clear, self-describing):
      {
        "toolName": "generateDocs",
        "args": {
          "fileName": "UserService.java",
          "author": "Vinay",
          "overwrite": true
        }
      }
   -> For a tool generateDocs(fileName, author, overwrite) we might describe the schema like this:
      {
        "toolName": "generateDocs",
        "description": "Generates documentation for a given Java file.",
        "argsSchema": {
          "type": "object",
          "properties": {
            "fileName": {
              "type": "string",
              "description": "Name of the Java source file"
            },
            "author": {
              "type": "string",
              "description": "The name of the author to include in the documentation"
            },
            "overwrite": {
              "type": "boolean",
              "description": "If true, overwrite existing documentation"
            }
          },
          "required": ["fileName"]
        }
      }
      -> Here:
        -> argsSchema clearly says “args is an object”.
        -> Each parameter is defined inside it with type + description.
        -> Required vs optional parameters are explicitly marked.
-> Now if we want the LLM (or a config file) to describe tools in JSON, then we need a way to parse JSON → Tool object. Here’s a simplified Tool class with a static method fromJson using Jackson:
   package com.example.agent;
   
   import com.fasterxml.jackson.databind.ObjectMapper;
   
   import java.io.IOException;
   import java.util.Map;
   
   public class Tool {
       private String toolName;
       private String description;
       private Map<String, Object> argsSchema; // simple schema for arguments
   
       // Default constructor for Jackson
       public Tool() {}
   
       public Tool(String toolName, String description, Map<String, Object> argsSchema) {
           this.toolName = toolName;
           this.description = description;
           this.argsSchema = argsSchema;
       }
   
       public String getToolName() {
           return toolName;
       }
   
       public String getDescription() {
           return description;
       }
   
       public Map<String, Object> getArgsSchema() {
           return argsSchema;
       }
   
       @Override
       public String toString() {
           return "Tool{" +
                   "toolName='" + toolName + '\'' +
                   ", description='" + description + '\'' +
                   ", argsSchema=" + argsSchema +
                   '}';
       }
   
       /**
        * Creates a Tool object from a JSON string.
        */
       public static Tool fromJson(String json) throws IOException {
           ObjectMapper mapper = new ObjectMapper();
           return mapper.readValue(json, Tool.class);
       }
   }

=============================================================================! Why Tool Design Matters !============================================================================================

Sometimes, if tools are too generic, such as a single listFiles or readFile method, the AI might struggle to use them correctly. For instance, an agent might attempt to read a file but specify the wrong directory, leading to errors. 
Instead, tools should be structured to enforce correctness while minimizing the agent’s margin for error. gents can use generic tools as well, but more specialized tools are easier to manage and less prone to misuse by the agent.
There is a trade-off between the specificity of tools and the flexibility they provide. More specific tools also limit reuse, so finding the right balance is crucial. When building an agent initially, err on the side of specificity.

Let’s assume that rather than a generic file agent, we are writing an agent that works with Java code and documentation. Instead of defining broad functions like:
  -> listFiles(String directory) → Returns all files in a specified directory.
  -> readFile(String filePath) → Reads a file from an arbitrary path.
  -> writeFile(String filePath, String content) → Writes to an arbitrary file.
We should define task-specific functions like:
  -> listJavaFiles() → Returns Java files only from the src/ directory.
  -> readJavaFile(String fileName) → Reads a Java file only from the src/ directory.
  -> writeDocumentation(String fileName, String content) → Writes documentation only to the docs/ directory.
In the context of the more limited scope of Java documentation, the constraints reduce the chances of incorrect agent behavior while making it clear what each tool does.
Example: Tool Definition with JSON
         String listJavaFilesJson = """
         {
           "toolName": "listJavaFiles",
           "description": "Returns a list of Java files in the src/ directory.",
           "parameters": {
             "type": "object",
             "properties": {},
             "required": []
           }
         }
         """;
         
         String readJavaFileJson = """
         {
           "toolName": "readJavaFile",
           "description": "Reads the content of a Java file from the src/ directory.",
           "parameters": {
             "type": "object",
             "properties": {
               "fileName": { 
                 "type": "string",
                 "description": "Name of the Java file to read (must end with .java)"
               }
             },
             "required": ["fileName"]
           }
         }
         """;
These tool definitions provide clear guidance to the LLM about what each tool does and what parameters it expects.

============================================================================! Best Practices for Tool Naming !===============================================================================================

Naming plays a crucial role in AI comprehension. If we name a tool procHandler, the AI might struggle to infer its purpose. Instead, naming it processFile provides better clarity.

Example: Naming Comparison
Poor Name	        Better Name
listJf	           listJavaFiles
readF	            readJavaFile
wrtDoc	           writeDocumentation

Even with well-named tools, we still need structured descriptions for disambiguation, especially in specialized domains.

============================================================================! Robust Error Handling in Tools !===============================================================================================

Each tool should be designed to handle errors gracefully and provide rich error messages back to the agent. This helps prevent failures and enables the agent to adjust its actions dynamically when unexpected issues occur.
Using our registerTool method and function structure, we can implement robust error handling:

// Register the tool implementation
agent.registerTool(readJavaFileJson, args -> {
    String fileName = (String) args.get("fileName");
    Path filePath = Paths.get("src", fileName);
    
    if (!fileName.endsWith(".java")) {
        // Return just the result - ActionResult is created in executeAction method
        return "Error: Invalid file type. Only Java files can be read. Call the listJavaFiles function to get a list of valid files.";
    }
    
    if (!Files.exists(filePath)) {
        return "Error: File '" + fileName + "' does not exist in the src/ directory. Call the listJavaFiles function to get a list of available files.";
    }
    
    try {
        return new String(Files.readAllBytes(filePath));
    } catch (Exception e) {
        return "Error reading file: " + e.getMessage();
    }
});
Remember that in our architecture, tool functions return raw results, and the executeAction method in the agent class creates the ActionResult objects. The error handling in our tool functions needs to adhere to this pattern.

Instructions in Error Messages (just-in-time guidance): When we know that certain tools will always be used together or that there is a right way to handle a particular error, we can provide that information back to the agent in the error message. 
For example, in our readJavaFile function, if the file does not exist, we can suggest that the agent call the listJavaFiles function to get an accurate list of file names.
   if (!Files.exists(filePath)) {
       return "Error: File '" + fileName + "' does not exist in the src/ directory. Call the listJavaFiles function to get a list of available files.";
   }
We could put this information into the original agent rules, but then the agent would have to remember it.And If you hardcode every possible relationship (like “if file not found → list files first”) into the system rules, the agent:
 -> Might get confused or apply the wrong one in a different context.
 -> Ends up with a bloated prompt → harder for the LLM to stay consistent.

Why “inject” the hint at error time?
When the readJavaFile tool fails, you don’t just return "File not found" (generic). Instead, you return a rich error message that contains: The error → "File 'abc.java' does not exist" and The next best step → "Call listJavaFiles to see available files."
This way:
 -> The LLM gets context-aware guidance exactly when it needs it.
 -> No need for global memory rules.
 -> Keeps your agent loop simpler and more modular.
Think of it like compiler hints in Java: If you miss a semicolon, the compiler says → “; expected”. It doesn’t dump the entire Java grammar in every error, it gives you a just-in-time, contextual nudge.
  if (!Files.exists(filePath)) {
      return "Error: File '" + fileName + "' does not exist in the src/ directory. " +
             "Suggestion: Call the listJavaFiles function to get a list of available files.";
  }
So the LLM sees the error + the suggested fix, and in the next step it will likely call listJavaFiles automatically. This pattern makes your agent self-correcting without making the ruleset unnecessarily heavy.

what happens after the agent calls listJavaFiles in response to the "file not found" error?
In this case, there are two possibility here
  -> Case A: Agent decides to stop here : It could just pass that list back to the user as the final result, saying: “The file you requested was not found. Here are the available files: [A.java, B.java, C.java]”
  -> Case B: Agent continues reasoning : The agent may check if one of those files matches or is “closest” to what the user meant. It could then automatically attempt readJavaFile again with a correct file name.
             Finally, it will use the terminate tool to return the content of that correct file to the user.
What actually happens depends on:How smart the LLM is AND Your agent rules
  -> How smart the LLM is: Some LLMs will “connect the dots” and retry automatically, others will just stop with the file list.
  -> Your agent rules → If you instruct: When a file is missing, call listJavaFiles, show the user the list, and let them choose” then the agent will stop at Case A. When a file is missing, call listJavaFiles and then retry reading if you find a close match”
                        then it will attempt Case B.

============================================================================! Tool Registration !================================================================================================================

Always remember registering tool should be clean and expressive:

  // Create agent instance
  AgentLoopFunctionCalling agent = new AgentLoopFunctionCalling(10);
  
  // Register tools
  agent.registerTool(listJavaFilesJson, args -> {
      try {
          File dir = new File("src");
          return Arrays.stream(dir.list())
              .filter(f -> f.endsWith(".java"))
              .collect(Collectors.toList());
      } catch (Exception e) {
          return "Error listing Java files: " + e.getMessage();
      }
  });
  
  agent.registerTool(readJavaFileJson, args -> {
      String fileName = (String) args.get("fileName");
      Path filePath = Paths.get("src", fileName);
      
      if (!fileName.endsWith(".java")) {
          return "Error: Invalid file type. Only Java files can be read.";
      }
      
      if (!Files.exists(filePath)) {
          return "Error: File '" + fileName + "' does not exist.";
      }
      
      try {
          return new String(Files.readAllBytes(filePath));
      } catch (Exception e) {
          return "Error reading file: " + e.getMessage();
      }
  });

===================================================================! Processing Result from tool function through ActionResult !====================================================================================

private ActionResult executeAction(Action action) {
    System.out.println("Executing: " + action.getToolName() + " with args " + action.getArgs());
    
    try {
        if (toolFunctions.containsKey(action.getToolName())) {
            // Get the raw result from the tool function
            Object result = toolFunctions.get(action.getToolName()).apply(action.getArgs());
            
            // If the result is a string that starts with "Error:", treat it as an error
            if (result instanceof String && ((String)result).startsWith("Error:")) {
                return new ActionResult(null, (String)result);
            } else {
                // Otherwise, it's a successful result
                return new ActionResult(result, null);
            }
        } else {
            return new ActionResult(null, "Unknown tool: " + action.getToolName());
        }
    } catch (Exception e) {
        return new ActionResult(null, 
            "Error executing " + action.getToolName() + ": " + e.getMessage());
    }
}

==============================================================================! Summary !=========================================================================================================================

When integrating AI into real-world environments, tool descriptions must be explicit, structured, and informative. By following these principles:
  -> Use descriptive names.
  -> Provide structured metadata via JSON schema.
  -> Keep tool implementations focused on core functionality.
  -> Return clear error messages with suggestions when appropriate.
  -> Let the agent framework handle consistent result processing.

This approach ensures that AI agents can interact with their environments effectively while minimizing incorrect or ambiguous tool usage. 


An AI Agent Loop is a design pattern in which a language model repeatedly reasons about the current state of a task, chooses an action to take, executes that action, and then re-evaluates the outcome. 
Instead of producing a single, static response, the model works in cycles, refining its approach based on feedback from tools, external systems, or its own reasoning. 
This makes it particularly powerful for problems where the next step cannot be determined in advance, such as navigating a file system, coordinating multiple APIs, or guiding a user through a multi-step workflow.

At the core of the loop are three stages: thinking, acting, and observing. In the "thinking" stage, the model decides what to do next based on the current context. In the "acting" stage, it calls a tool, runs a function, or produces an output. 
Then, in the "observing" stage, it examines the result of that action—whether success, failure, or partial progress—and incorporates that feedback into the next cycle of reasoning. 
This iterative process continues until the agent decides it has reached the goal or a termination condition is met.

The strength of the agent loop lies in its flexibility. Unlike traditional programs that follow a rigid sequence of steps, an AI agent loop can adapt dynamically, handling unexpected errors (such as a missing file)
by rethinking its plan and trying an alternative action. It also allows developers to integrate domain-specific knowledge through tools—such as database queries, file operations, or API calls—while leaving the 
higher-level decision-making to the model. This combination makes it useful in fields like customer support, research assistance, automation, and even software development.

However, an agent loop is not without challenges. Because the model is reasoning in cycles, it can sometimes fall into infinite loops, repeating the same actions without progress. It can also generate unnecessary 
tool calls if not guided properly. To mitigate these risks, developers often set constraints—such as a maximum number of steps, clear termination signals, or fallback behaviors. When designed well, though, 
the agent loop provides a powerful way to make AI systems not just reactive, but proactive and resilient in solving complex, real-world problems.
